{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from pytrends.request import TrendReq\n",
    "import time\n",
    "import math\n",
    "pytrend = TrendReq(hl='en-US', tz=360)\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import PokemonData using pandas\n",
    "#including popularity of each pokemon found in a reddit thread\n",
    "pokemonData=pd.read_csv('SourceData/PokemonDataV2 - DistinctCheck.csv', header = 0)\n",
    "\n",
    "pokemonDataUnmodified = []\n",
    "\n",
    "with open(\"SourceData/PokemonDataV2 - DistinctCheck.csv\", \"r\") as data_file:\n",
    "    for row in data_file:\n",
    "        tempRow = row.strip()\n",
    "        tempRow = tempRow.split(\",\")\n",
    "        pokemonDataUnmodified.append(list(tempRow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Ndex',\n",
       "  'PokÃ©mon',\n",
       "  'Variance',\n",
       "  'Generation',\n",
       "  'Evolution',\n",
       "  'Rarity',\n",
       "  'Popularity',\n",
       "  'NewSnap'],\n",
       " ['1', 'Bulbasaur', '', '1', '1', 'Starter', '710', '1'],\n",
       " ['2', 'Ivysaur', '', '1', '2', 'Starter', '83', '0'],\n",
       " ['3', 'Venusaur', '', '1', '3', 'Starter', '127', '1'],\n",
       " ['4', 'Charmander', '', '1', '1', 'Starter', '374', '1'],\n",
       " ['5', 'Charmeleon', '', '1', '2', 'Starter', '70', '0'],\n",
       " ['6', 'Charizard', '', '1', '3', 'Starter', '1107', '1'],\n",
       " ['7', 'Squirtle', '', '1', '1', 'Starter', '523', '1'],\n",
       " ['8', 'Wartortle', '', '1', '2', 'Starter', '133', '0']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pokemonDataUnmodified[0:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', 'Bulbasaur', '', '1', '1', 'Starter', '710', '1'],\n",
       " ['2', 'Ivysaur', '', '1', '2', 'Starter', '83', '0'],\n",
       " ['3', 'Venusaur', '', '1', '3', 'Starter', '127', '1'],\n",
       " ['4', 'Charmander', '', '1', '1', 'Starter', '374', '1'],\n",
       " ['5', 'Charmeleon', '', '1', '2', 'Starter', '70', '0'],\n",
       " ['6', 'Charizard', '', '1', '3', 'Starter', '1107', '1'],\n",
       " ['7', 'Squirtle', '', '1', '1', 'Starter', '523', '1'],\n",
       " ['8', 'Wartortle', '', '1', '2', 'Starter', '133', '0'],\n",
       " ['9', 'Blastoise', '', '1', '3', 'Starter', '410', '1']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#delete row with headers\n",
    "\n",
    "del pokemonDataUnmodified[0]\n",
    "pokemonDataUnmodified[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove columns that will not be used. name isn't needed and Ndex is a primary key (more or less)\n",
    "pokemonData = pokemonData.drop(['Pokémon'], axis=1) \n",
    "pokemonData = pokemonData.drop(['Ndex'], axis=1) \n",
    "\n",
    "#change data in each column to include what column they are in\n",
    "#this will be VERY useful later on\n",
    "pokemonData['Variance'] = 'Variance_' + pokemonData['Variance']\n",
    "pokemonData['Generation'] = 'Generation_' + pokemonData['Generation'].astype(str)\n",
    "pokemonData['Evolution'] = 'Evolution_' + pokemonData['Evolution'].astype(str)\n",
    "pokemonData['Rarity'] = 'Rarity_' + pokemonData['Rarity']\n",
    "\n",
    "#change the NewSnap column to 0/1, only include initially included in game (no DLC)\n",
    "def newSnapCheck(data):\n",
    "  if data['NewSnap'] == 1:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "#fill in nan values in popularity because decision tree needs values on all spots. going with zero. \n",
    "def popularityCheck(data):\n",
    "  if math.isnan(data['Popularity']):\n",
    "    return 0\n",
    "  else:\n",
    "    return data['Popularity']\n",
    "\n",
    "pokemonData['NewSnap'] = pokemonData.apply(newSnapCheck, axis=1)\n",
    "pokemonData['Popularity'] = pokemonData.apply(popularityCheck, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do one hot encoding (aka dummy variables in pandas) on categorical columns\n",
    "\n",
    "variance_occurance = pokemonData['Variance']\n",
    "variance_occurance = pd.Series(variance_occurance)\n",
    "variance_dummy = pd.get_dummies(variance_occurance)\n",
    "\n",
    "generation_occurance = pokemonData['Generation']\n",
    "generation_occurance = pd.Series(generation_occurance)\n",
    "generation_dummy = pd.get_dummies(generation_occurance)\n",
    "\n",
    "evolution_occurance = pokemonData['Evolution']\n",
    "evolution_occurance = pd.Series(evolution_occurance)\n",
    "evolution_dummy = pd.get_dummies(evolution_occurance)\n",
    "\n",
    "rarity_occurance = pokemonData['Rarity']\n",
    "rarity_occurance = pd.Series(rarity_occurance)\n",
    "rarity_dummy = pd.get_dummies(rarity_occurance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attach the dummy variables\n",
    "pokemonData = pd.concat([pokemonData, variance_dummy], axis=1)\n",
    "pokemonData = pd.concat([pokemonData, generation_dummy], axis=1)\n",
    "pokemonData = pd.concat([pokemonData, evolution_dummy], axis=1)\n",
    "pokemonData = pd.concat([pokemonData, rarity_dummy], axis=1)\n",
    "\n",
    "#remove the categorical columns\n",
    "pokemonData = pokemonData.drop(['Variance'], axis=1) \n",
    "pokemonData = pokemonData.drop(['Generation'], axis=1) \n",
    "pokemonData = pokemonData.drop(['Evolution'], axis=1) \n",
    "pokemonData = pokemonData.drop(['Rarity'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Popularity</th>\n",
       "      <th>NewSnap</th>\n",
       "      <th>Variance_Alohan</th>\n",
       "      <th>Variance_Galarian</th>\n",
       "      <th>Variance_Multiple</th>\n",
       "      <th>Generation_1</th>\n",
       "      <th>Generation_2</th>\n",
       "      <th>Generation_3</th>\n",
       "      <th>Generation_4</th>\n",
       "      <th>Generation_5</th>\n",
       "      <th>...</th>\n",
       "      <th>Evolution_0</th>\n",
       "      <th>Evolution_1</th>\n",
       "      <th>Evolution_2</th>\n",
       "      <th>Evolution_3</th>\n",
       "      <th>Rarity_Ancient</th>\n",
       "      <th>Rarity_Legendary</th>\n",
       "      <th>Rarity_Mythical</th>\n",
       "      <th>Rarity_Standard</th>\n",
       "      <th>Rarity_Starter</th>\n",
       "      <th>Rarity_Sub-Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>710.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>127.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>374.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1107.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>523.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>133.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>410.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Popularity  NewSnap  Variance_Alohan  Variance_Galarian  Variance_Multiple  \\\n",
       "0       710.0        1                0                  0                  0   \n",
       "1        83.0        0                0                  0                  0   \n",
       "2       127.0        1                0                  0                  0   \n",
       "3       374.0        1                0                  0                  0   \n",
       "4        70.0        0                0                  0                  0   \n",
       "5      1107.0        1                0                  0                  0   \n",
       "6       523.0        1                0                  0                  0   \n",
       "7       133.0        0                0                  0                  0   \n",
       "8       410.0        1                0                  0                  0   \n",
       "\n",
       "   Generation_1  Generation_2  Generation_3  Generation_4  Generation_5  ...  \\\n",
       "0             1             0             0             0             0  ...   \n",
       "1             1             0             0             0             0  ...   \n",
       "2             1             0             0             0             0  ...   \n",
       "3             1             0             0             0             0  ...   \n",
       "4             1             0             0             0             0  ...   \n",
       "5             1             0             0             0             0  ...   \n",
       "6             1             0             0             0             0  ...   \n",
       "7             1             0             0             0             0  ...   \n",
       "8             1             0             0             0             0  ...   \n",
       "\n",
       "   Evolution_0  Evolution_1  Evolution_2  Evolution_3  Rarity_Ancient  \\\n",
       "0            0            1            0            0               0   \n",
       "1            0            0            1            0               0   \n",
       "2            0            0            0            1               0   \n",
       "3            0            1            0            0               0   \n",
       "4            0            0            1            0               0   \n",
       "5            0            0            0            1               0   \n",
       "6            0            1            0            0               0   \n",
       "7            0            0            1            0               0   \n",
       "8            0            0            0            1               0   \n",
       "\n",
       "   Rarity_Legendary  Rarity_Mythical  Rarity_Standard  Rarity_Starter  \\\n",
       "0                 0                0                0               1   \n",
       "1                 0                0                0               1   \n",
       "2                 0                0                0               1   \n",
       "3                 0                0                0               1   \n",
       "4                 0                0                0               1   \n",
       "5                 0                0                0               1   \n",
       "6                 0                0                0               1   \n",
       "7                 0                0                0               1   \n",
       "8                 0                0                0               1   \n",
       "\n",
       "   Rarity_Sub-Legendary  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "5                     0  \n",
       "6                     0  \n",
       "7                     0  \n",
       "8                     0  \n",
       "\n",
       "[9 rows x 23 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pokemonData.head(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backwards Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Popularity', 'NewSnap', 'Variance_Alohan', 'Variance_Galarian',\n",
       "       'Variance_Multiple', 'Generation_1', 'Generation_2', 'Generation_3',\n",
       "       'Generation_4', 'Generation_5', 'Generation_6', 'Generation_7',\n",
       "       'Generation_8', 'Evolution_0', 'Evolution_1', 'Evolution_2',\n",
       "       'Evolution_3', 'Rarity_Ancient', 'Rarity_Legendary', 'Rarity_Mythical',\n",
       "       'Rarity_Standard', 'Rarity_Starter', 'Rarity_Sub-Legendary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pokemonData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ols had issues with the '-' in the column name. Changed column name to get it to work\n",
    "pokemonData.columns = pokemonData.columns.str.replace('Rarity_Sub-Legendary', 'Rarity_SubLegendary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>NewSnap</td>     <th>  R-squared:         </th> <td>   0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   5.213</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 03 Mar 2023</td> <th>  Prob (F-statistic):</th> <td>4.73e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:10:06</td>     <th>  Log-Likelihood:    </th> <td> -457.13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   898</td>      <th>  AIC:               </th> <td>   954.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   878</td>      <th>  BIC:               </th> <td>   1050.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    19</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>           <td>    0.0866</td> <td>    0.021</td> <td>    4.196</td> <td> 0.000</td> <td>    0.046</td> <td>    0.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Popularity</th>          <td>    0.0008</td> <td>    0.000</td> <td>    5.613</td> <td> 0.000</td> <td>    0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Variance_Alohan</th>     <td>    0.3107</td> <td>    0.105</td> <td>    2.951</td> <td> 0.003</td> <td>    0.104</td> <td>    0.517</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Variance_Galarian</th>   <td>   -0.0727</td> <td>    0.099</td> <td>   -0.733</td> <td> 0.464</td> <td>   -0.267</td> <td>    0.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Variance_Multiple</th>   <td>    0.8247</td> <td>    0.409</td> <td>    2.015</td> <td> 0.044</td> <td>    0.021</td> <td>    1.628</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Generation_1</th>        <td>   -0.0480</td> <td>    0.036</td> <td>   -1.327</td> <td> 0.185</td> <td>   -0.119</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Generation_2</th>        <td>    0.0821</td> <td>    0.039</td> <td>    2.114</td> <td> 0.035</td> <td>    0.006</td> <td>    0.158</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Generation_3</th>        <td>    0.0098</td> <td>    0.034</td> <td>    0.289</td> <td> 0.772</td> <td>   -0.057</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Generation_4</th>        <td>    0.0203</td> <td>    0.037</td> <td>    0.546</td> <td> 0.585</td> <td>   -0.053</td> <td>    0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Generation_5</th>        <td>   -0.0175</td> <td>    0.032</td> <td>   -0.549</td> <td> 0.583</td> <td>   -0.080</td> <td>    0.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Generation_6</th>        <td>    0.0927</td> <td>    0.044</td> <td>    2.086</td> <td> 0.037</td> <td>    0.005</td> <td>    0.180</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Generation_7</th>        <td>    0.0484</td> <td>    0.042</td> <td>    1.163</td> <td> 0.245</td> <td>   -0.033</td> <td>    0.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Generation_8</th>        <td>   -0.1012</td> <td>    0.041</td> <td>   -2.479</td> <td> 0.013</td> <td>   -0.181</td> <td>   -0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Evolution_0</th>         <td>    0.1092</td> <td>    0.032</td> <td>    3.371</td> <td> 0.001</td> <td>    0.046</td> <td>    0.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Evolution_1</th>         <td>    0.0010</td> <td>    0.024</td> <td>    0.042</td> <td> 0.966</td> <td>   -0.047</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Evolution_2</th>         <td>   -0.0117</td> <td>    0.024</td> <td>   -0.488</td> <td> 0.625</td> <td>   -0.059</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Evolution_3</th>         <td>   -0.0119</td> <td>    0.036</td> <td>   -0.334</td> <td> 0.739</td> <td>   -0.082</td> <td>    0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Rarity_Ancient</th>      <td>    0.1275</td> <td>    0.074</td> <td>    1.717</td> <td> 0.086</td> <td>   -0.018</td> <td>    0.273</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Rarity_Legendary</th>    <td>   -0.1128</td> <td>    0.076</td> <td>   -1.490</td> <td> 0.136</td> <td>   -0.261</td> <td>    0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Rarity_Mythical</th>     <td>    0.0225</td> <td>    0.080</td> <td>    0.283</td> <td> 0.777</td> <td>   -0.134</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Rarity_Standard</th>     <td>    0.0965</td> <td>    0.032</td> <td>    3.007</td> <td> 0.003</td> <td>    0.034</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Rarity_Starter</th>      <td>    0.1325</td> <td>    0.051</td> <td>    2.581</td> <td> 0.010</td> <td>    0.032</td> <td>    0.233</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Rarity_SubLegendary</th> <td>   -0.1796</td> <td>    0.060</td> <td>   -2.990</td> <td> 0.003</td> <td>   -0.298</td> <td>   -0.062</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>129.614</td> <th>  Durbin-Watson:     </th> <td>   1.914</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 186.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.107</td>  <th>  Prob(JB):          </th> <td>3.81e-41</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.727</td>  <th>  Cond. No.          </th> <td>1.47e+18</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 6.85e-30. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                NewSnap   R-squared:                       0.101\n",
       "Model:                            OLS   Adj. R-squared:                  0.082\n",
       "Method:                 Least Squares   F-statistic:                     5.213\n",
       "Date:                Fri, 03 Mar 2023   Prob (F-statistic):           4.73e-12\n",
       "Time:                        09:10:06   Log-Likelihood:                -457.13\n",
       "No. Observations:                 898   AIC:                             954.3\n",
       "Df Residuals:                     878   BIC:                             1050.\n",
       "Df Model:                          19                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=======================================================================================\n",
       "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "Intercept               0.0866      0.021      4.196      0.000       0.046       0.127\n",
       "Popularity              0.0008      0.000      5.613      0.000       0.001       0.001\n",
       "Variance_Alohan         0.3107      0.105      2.951      0.003       0.104       0.517\n",
       "Variance_Galarian      -0.0727      0.099     -0.733      0.464      -0.267       0.122\n",
       "Variance_Multiple       0.8247      0.409      2.015      0.044       0.021       1.628\n",
       "Generation_1           -0.0480      0.036     -1.327      0.185      -0.119       0.023\n",
       "Generation_2            0.0821      0.039      2.114      0.035       0.006       0.158\n",
       "Generation_3            0.0098      0.034      0.289      0.772      -0.057       0.076\n",
       "Generation_4            0.0203      0.037      0.546      0.585      -0.053       0.093\n",
       "Generation_5           -0.0175      0.032     -0.549      0.583      -0.080       0.045\n",
       "Generation_6            0.0927      0.044      2.086      0.037       0.005       0.180\n",
       "Generation_7            0.0484      0.042      1.163      0.245      -0.033       0.130\n",
       "Generation_8           -0.1012      0.041     -2.479      0.013      -0.181      -0.021\n",
       "Evolution_0             0.1092      0.032      3.371      0.001       0.046       0.173\n",
       "Evolution_1             0.0010      0.024      0.042      0.966      -0.047       0.049\n",
       "Evolution_2            -0.0117      0.024     -0.488      0.625      -0.059       0.035\n",
       "Evolution_3            -0.0119      0.036     -0.334      0.739      -0.082       0.058\n",
       "Rarity_Ancient          0.1275      0.074      1.717      0.086      -0.018       0.273\n",
       "Rarity_Legendary       -0.1128      0.076     -1.490      0.136      -0.261       0.036\n",
       "Rarity_Mythical         0.0225      0.080      0.283      0.777      -0.134       0.179\n",
       "Rarity_Standard         0.0965      0.032      3.007      0.003       0.034       0.159\n",
       "Rarity_Starter          0.1325      0.051      2.581      0.010       0.032       0.233\n",
       "Rarity_SubLegendary    -0.1796      0.060     -2.990      0.003      -0.298      -0.062\n",
       "==============================================================================\n",
       "Omnibus:                      129.614   Durbin-Watson:                   1.914\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              186.138\n",
       "Skew:                           1.107   Prob(JB):                     3.81e-41\n",
       "Kurtosis:                       2.727   Cond. No.                     1.47e+18\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 6.85e-30. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For all sms models, use the dataframe loan_reg.\n",
    "#Using est = smf.ols(formula='y ~ X variables, data).fit() run a multiple regression.  Name it est.\n",
    "OLSCheck = smf.ols(formula='NewSnap ~ Popularity +\\\n",
    "Variance_Alohan + Variance_Galarian +\\\n",
    "Variance_Multiple + Generation_1 +\\\n",
    "Generation_2 + Generation_3 +\\\n",
    "Generation_4 + Generation_5 +\\\n",
    "Generation_6 + Generation_7 +\\\n",
    "Generation_8 + Evolution_0 +\\\n",
    "Evolution_1 + Evolution_2 +\\\n",
    "Evolution_3 + Rarity_Ancient +\\\n",
    "Rarity_Legendary + Rarity_Mythical +\\\n",
    "Rarity_Standard + Rarity_Starter +\\\n",
    "Rarity_SubLegendary', data= pokemonData).fit()\n",
    "OLSCheck.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analyze the summary statistics and conduct the steps to eliminate all non-significant models\n",
    "- After all of the variables with p-values above 0.05 are eliminated, \n",
    "- Analyze the final model and give some insight into the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>NewSnap</td>     <th>  R-squared:         </th> <td>   0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   9.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 03 Mar 2023</td> <th>  Prob (F-statistic):</th> <td>2.13e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:18:26</td>     <th>  Log-Likelihood:    </th> <td> -461.29</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   898</td>      <th>  AIC:               </th> <td>   944.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   887</td>      <th>  BIC:               </th> <td>   997.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>           <td>    0.1083</td> <td>    0.057</td> <td>    1.915</td> <td> 0.056</td> <td>   -0.003</td> <td>    0.219</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Popularity</th>          <td>    0.0007</td> <td>    0.000</td> <td>    5.625</td> <td> 0.000</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Variance_Alohan</th>     <td>    0.2693</td> <td>    0.101</td> <td>    2.678</td> <td> 0.008</td> <td>    0.072</td> <td>    0.467</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Variance_Multiple</th>   <td>    0.7882</td> <td>    0.407</td> <td>    1.935</td> <td> 0.053</td> <td>   -0.011</td> <td>    1.588</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Generation_2</th>        <td>    0.0850</td> <td>    0.044</td> <td>    1.928</td> <td> 0.054</td> <td>   -0.002</td> <td>    0.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Generation_6</th>        <td>    0.0957</td> <td>    0.051</td> <td>    1.867</td> <td> 0.062</td> <td>   -0.005</td> <td>    0.196</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Generation_8</th>        <td>   -0.1021</td> <td>    0.047</td> <td>   -2.174</td> <td> 0.030</td> <td>   -0.194</td> <td>   -0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Evolution_0</th>         <td>    0.1035</td> <td>    0.042</td> <td>    2.440</td> <td> 0.015</td> <td>    0.020</td> <td>    0.187</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Rarity_Standard</th>     <td>    0.0674</td> <td>    0.056</td> <td>    1.214</td> <td> 0.225</td> <td>   -0.042</td> <td>    0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Rarity_Starter</th>      <td>    0.1116</td> <td>    0.073</td> <td>    1.531</td> <td> 0.126</td> <td>   -0.031</td> <td>    0.255</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Rarity_SubLegendary</th> <td>   -0.1844</td> <td>    0.078</td> <td>   -2.361</td> <td> 0.018</td> <td>   -0.338</td> <td>   -0.031</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>133.366</td> <th>  Durbin-Watson:     </th> <td>   1.903</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 194.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.131</td>  <th>  Prob(JB):          </th> <td>7.40e-43</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.734</td>  <th>  Cond. No.          </th> <td>3.85e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.85e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                NewSnap   R-squared:                       0.093\n",
       "Model:                            OLS   Adj. R-squared:                  0.083\n",
       "Method:                 Least Squares   F-statistic:                     9.096\n",
       "Date:                Fri, 03 Mar 2023   Prob (F-statistic):           2.13e-14\n",
       "Time:                        09:18:26   Log-Likelihood:                -461.29\n",
       "No. Observations:                 898   AIC:                             944.6\n",
       "Df Residuals:                     887   BIC:                             997.4\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=======================================================================================\n",
       "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "Intercept               0.1083      0.057      1.915      0.056      -0.003       0.219\n",
       "Popularity              0.0007      0.000      5.625      0.000       0.000       0.001\n",
       "Variance_Alohan         0.2693      0.101      2.678      0.008       0.072       0.467\n",
       "Variance_Multiple       0.7882      0.407      1.935      0.053      -0.011       1.588\n",
       "Generation_2            0.0850      0.044      1.928      0.054      -0.002       0.172\n",
       "Generation_6            0.0957      0.051      1.867      0.062      -0.005       0.196\n",
       "Generation_8           -0.1021      0.047     -2.174      0.030      -0.194      -0.010\n",
       "Evolution_0             0.1035      0.042      2.440      0.015       0.020       0.187\n",
       "Rarity_Standard         0.0674      0.056      1.214      0.225      -0.042       0.176\n",
       "Rarity_Starter          0.1116      0.073      1.531      0.126      -0.031       0.255\n",
       "Rarity_SubLegendary    -0.1844      0.078     -2.361      0.018      -0.338      -0.031\n",
       "==============================================================================\n",
       "Omnibus:                      133.366   Durbin-Watson:                   1.903\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              194.019\n",
       "Skew:                           1.131   Prob(JB):                     7.40e-43\n",
       "Kurtosis:                       2.734   Cond. No.                     3.85e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.85e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLSCheck = smf.ols(formula='NewSnap ~ Popularity +\\\n",
    "Variance_Alohan +\\\n",
    "Variance_Multiple +\\\n",
    "Generation_2 +\\\n",
    "Generation_6 +\\\n",
    "Generation_8 + Evolution_0 +\\\n",
    "Rarity_Standard + Rarity_Starter +\\\n",
    "Rarity_SubLegendary', data= pokemonData).fit()\n",
    "OLSCheck.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>NewSnap</td>     <th>  R-squared:         </th> <td>   0.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   15.51</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 03 Mar 2023</td> <th>  Prob (F-statistic):</th> <td>1.19e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:19:45</td>     <th>  Log-Likelihood:    </th> <td> -467.70</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   898</td>      <th>  AIC:               </th> <td>   947.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   892</td>      <th>  BIC:               </th> <td>   976.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>           <td>    0.1969</td> <td>    0.018</td> <td>   11.046</td> <td> 0.000</td> <td>    0.162</td> <td>    0.232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Popularity</th>          <td>    0.0008</td> <td>    0.000</td> <td>    6.251</td> <td> 0.000</td> <td>    0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Variance_Alohan</th>     <td>    0.2465</td> <td>    0.101</td> <td>    2.451</td> <td> 0.014</td> <td>    0.049</td> <td>    0.444</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Generation_8</th>        <td>   -0.1201</td> <td>    0.046</td> <td>   -2.590</td> <td> 0.010</td> <td>   -0.211</td> <td>   -0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Evolution_0</th>         <td>    0.0776</td> <td>    0.039</td> <td>    2.003</td> <td> 0.045</td> <td>    0.002</td> <td>    0.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Rarity_SubLegendary</th> <td>   -0.2433</td> <td>    0.068</td> <td>   -3.577</td> <td> 0.000</td> <td>   -0.377</td> <td>   -0.110</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>136.078</td> <th>  Durbin-Watson:     </th> <td>   1.901</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 198.277</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.142</td>  <th>  Prob(JB):          </th> <td>8.80e-44</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.705</td>  <th>  Cond. No.          </th> <td>    947.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                NewSnap   R-squared:                       0.080\n",
       "Model:                            OLS   Adj. R-squared:                  0.075\n",
       "Method:                 Least Squares   F-statistic:                     15.51\n",
       "Date:                Fri, 03 Mar 2023   Prob (F-statistic):           1.19e-14\n",
       "Time:                        09:19:45   Log-Likelihood:                -467.70\n",
       "No. Observations:                 898   AIC:                             947.4\n",
       "Df Residuals:                     892   BIC:                             976.2\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=======================================================================================\n",
       "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "Intercept               0.1969      0.018     11.046      0.000       0.162       0.232\n",
       "Popularity              0.0008      0.000      6.251      0.000       0.001       0.001\n",
       "Variance_Alohan         0.2465      0.101      2.451      0.014       0.049       0.444\n",
       "Generation_8           -0.1201      0.046     -2.590      0.010      -0.211      -0.029\n",
       "Evolution_0             0.0776      0.039      2.003      0.045       0.002       0.154\n",
       "Rarity_SubLegendary    -0.2433      0.068     -3.577      0.000      -0.377      -0.110\n",
       "==============================================================================\n",
       "Omnibus:                      136.078   Durbin-Watson:                   1.901\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              198.277\n",
       "Skew:                           1.142   Prob(JB):                     8.80e-44\n",
       "Kurtosis:                       2.705   Cond. No.                         947.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLSCheck = smf.ols(formula='NewSnap ~ Popularity +\\\n",
    "Variance_Alohan +\\\n",
    "Generation_8 + Evolution_0 +\\\n",
    "Rarity_SubLegendary', data= pokemonData).fit()\n",
    "OLSCheck.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Statistically Non-significant Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Popularity', 'NewSnap', 'Variance_Alohan', 'Variance_Galarian',\n",
       "       'Variance_Multiple', 'Generation_1', 'Generation_2', 'Generation_3',\n",
       "       'Generation_4', 'Generation_5', 'Generation_6', 'Generation_7',\n",
       "       'Generation_8', 'Evolution_0', 'Evolution_1', 'Evolution_2',\n",
       "       'Evolution_3', 'Rarity_Ancient', 'Rarity_Legendary', 'Rarity_Mythical',\n",
       "       'Rarity_Standard', 'Rarity_Starter', 'Rarity_SubLegendary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the dataset to only include the columns that were statistically significant\n",
    "pokemonData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Popularity', 'NewSnap', 'Variance_Alohan', 'Generation_8',\n",
       "       'Evolution_0', 'Rarity_SubLegendary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pokemonData = pokemonData.drop(['Variance_Galarian'], axis=1) \n",
    "pokemonData = pokemonData.drop(['Variance_Multiple'], axis=1) \n",
    "pokemonData = pokemonData.drop(['Generation_1'], axis=1) \n",
    "pokemonData = pokemonData.drop(['Generation_2'], axis=1) \n",
    "pokemonData = pokemonData.drop(['Generation_3'], axis=1) \n",
    "pokemonData = pokemonData.drop(['Generation_4'], axis=1) \n",
    "pokemonData = pokemonData.drop(['Generation_5'], axis=1) \n",
    "pokemonData = pokemonData.drop(['Generation_6'], axis=1) \n",
    "pokemonData = pokemonData.drop(['Generation_7'], axis=1) \n",
    "pokemonData = pokemonData.drop(['Evolution_1'], axis=1) \n",
    "pokemonData = pokemonData.drop(['Evolution_2'], axis=1) \n",
    "pokemonData = pokemonData.drop(['Evolution_3'], axis=1)\n",
    "pokemonData = pokemonData.drop(['Rarity_Ancient'], axis=1)\n",
    "pokemonData = pokemonData.drop(['Rarity_Legendary'], axis=1)\n",
    "pokemonData = pokemonData.drop(['Rarity_Mythical'], axis=1)\n",
    "pokemonData = pokemonData.drop(['Rarity_Standard'], axis=1)\n",
    "pokemonData = pokemonData.drop(['Rarity_Starter'], axis=1)\n",
    "\n",
    "pokemonData.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate the NewSnap column to test for it\n",
    "y = pokemonData['NewSnap']\n",
    "X = pokemonData.drop(['NewSnap'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data for training/testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 628 entries, 246 to 132\n",
      "Data columns (total 5 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Popularity           628 non-null    float64\n",
      " 1   Variance_Alohan      628 non-null    uint8  \n",
      " 2   Generation_8         628 non-null    uint8  \n",
      " 3   Evolution_0          628 non-null    uint8  \n",
      " 4   Rarity_SubLegendary  628 non-null    uint8  \n",
      "dtypes: float64(1), uint8(4)\n",
      "memory usage: 12.3 KB\n"
     ]
    }
   ],
   "source": [
    "#check to make sure the columns look clean in training\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 270 entries, 186 to 311\n",
      "Data columns (total 5 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Popularity           270 non-null    float64\n",
      " 1   Variance_Alohan      270 non-null    uint8  \n",
      " 2   Generation_8         270 non-null    uint8  \n",
      " 3   Evolution_0          270 non-null    uint8  \n",
      " 4   Rarity_SubLegendary  270 non-null    uint8  \n",
      "dtypes: float64(1), uint8(4)\n",
      "memory usage: 5.3 KB\n"
     ]
    }
   ],
   "source": [
    "#check to make sure the columns look clean in testing\n",
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do a decision tree classifier based on the training sets\n",
    "classifier=DecisionTreeClassifier()\n",
    "classifier=classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the created prediction model on the testing set\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.91      0.83       201\n",
      "           1       0.44      0.22      0.29        69\n",
      "\n",
      "    accuracy                           0.73       270\n",
      "   macro avg       0.61      0.56      0.56       270\n",
      "weighted avg       0.69      0.73      0.69       270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check results of the decision tree\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[182  19]\n",
      " [ 54  15]]\n"
     ]
    }
   ],
   "source": [
    "#get confusion matrix for counts\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "attachments": {
    "8b1d0031-7802-41c0-902c-c8d54b0d260b.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:8b1d0031-7802-41c0-902c-c8d54b0d260b.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "      <th>Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.843397</td>\n",
       "      <td>Popularity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.104383</td>\n",
       "      <td>Evolution_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.028623</td>\n",
       "      <td>Variance_Alohan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022510</td>\n",
       "      <td>Rarity_SubLegendary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001086</td>\n",
       "      <td>Generation_8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Importance             Features\n",
       "0    0.843397           Popularity\n",
       "3    0.104383          Evolution_0\n",
       "1    0.028623      Variance_Alohan\n",
       "4    0.022510  Rarity_SubLegendary\n",
       "2    0.001086         Generation_8"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find importance based off classifier\n",
    "dt_fi = pd.DataFrame(classifier.feature_importances_)\n",
    "names = pd.DataFrame(list(X.columns))\n",
    "df_feat_imp = pd.concat([dt_fi, names], axis = 1)\n",
    "\n",
    "df_feat_imp.columns = ['Importance', 'Features']\n",
    "df_feat_imp.sort_values('Importance', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original model had a 70% accuracy. Elimination caused a 3% increase in accuracy. It also uses a lot less memory when having to calculate the model since there are only 5 variables being used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run a random forst using the following code:\n",
    "rf = RandomForestClassifier(n_estimators = 90, max_depth = 10)\n",
    "rf = rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7185185185185186\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.92      0.83       201\n",
      "           1       0.37      0.14      0.21        69\n",
      "\n",
      "    accuracy                           0.72       270\n",
      "   macro avg       0.56      0.53      0.52       270\n",
      "weighted avg       0.66      0.72      0.67       270\n",
      "\n",
      "[[184  17]\n",
      " [ 59  10]]\n"
     ]
    }
   ],
   "source": [
    "#Print Scores\n",
    "score = rf.score(X_test, y_test)\n",
    "print(score)\n",
    "rf_pred = rf.predict(X_test)\n",
    "print(classification_report(y_test, rf_pred))\n",
    "print(confusion_matrix(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the model type to random forest didn't seem to do anything to improve the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7481481481481481\n"
     ]
    }
   ],
   "source": [
    "#Create a Logistic Regression classifier using:\n",
    "logr = LogisticRegression()\n",
    "logr.fit(X_train, y_train)\n",
    "score = logr.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a predicted variable from X_test\n",
    "log_pred = logr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[197   4]\n",
      " [ 64   5]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.98      0.85       201\n",
      "           1       0.56      0.07      0.13        69\n",
      "\n",
      "    accuracy                           0.75       270\n",
      "   macro avg       0.66      0.53      0.49       270\n",
      "weighted avg       0.70      0.75      0.67       270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, log_pred))\n",
    "print(\"\")\n",
    "print(classification_report(y_test, log_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression was better at predicting which Pokemon where going to be excluded from the game, but had a harder time predicting which would be included. 75% accuracy, but it seemed to favor categorizing Pokemon to not being included. Only 5 Pokemon where accurately predicted to be in the game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with Standard Scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create scaled sets of the X dataframe\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data for test/train for the scaled dataframe\n",
    "X_trainSC, X_testSC, y_trainSC, y_testSC = train_test_split(X_scaled, y, test_size = 0.3, random_state = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7818471337579618\n"
     ]
    }
   ],
   "source": [
    "#Rerun a logistic regression using the standard scalar datasets.\n",
    "logr = LogisticRegression()\n",
    "logr.fit(X_trainSC, y_trainSC)\n",
    "score = logr.score(X_trainSC, y_trainSC)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_predSC = logr.predict(X_testSC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[197   4]\n",
      " [ 64   5]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.98      0.85       201\n",
      "           1       0.56      0.07      0.13        69\n",
      "\n",
      "    accuracy                           0.75       270\n",
      "   macro avg       0.66      0.53      0.49       270\n",
      "weighted avg       0.70      0.75      0.67       270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print the score, confusion matrix, and classification report\n",
    "print(confusion_matrix(y_testSC, log_predSC))\n",
    "print(\"\")\n",
    "print(classification_report(y_testSC, log_predSC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression with Standard Scalar had the exact same results as regular Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
